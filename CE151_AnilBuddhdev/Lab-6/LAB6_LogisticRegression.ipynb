{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LAB6_LogisticRegression.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVOBlnlr9MNE"
      },
      "source": [
        "#Importing libraries\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import io\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y20_Wn7t-gk0"
      },
      "source": [
        "# reading the csv file, del 2 columns from the file, checking first few rows of the file\n",
        "data = pd.read_csv('BuyComputer.csv')\n",
        "data.drop(columns=['User ID',],axis=1,inplace=True)\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyPkvP4p_45Q"
      },
      "source": [
        "#Declare label as last column in the source file\n",
        "label=data['Purchased']\n",
        "label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWwwaaHNAdhE"
      },
      "source": [
        "#Declaring X as all columns excluding last\n",
        "X=data[['Age','EstimatedSalary']]\n",
        "X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuvPX95MAwfm"
      },
      "source": [
        "# Splitting data\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,label,test_size=0.3,random_state=29)\n",
        "X_train, X_test, y_train, y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oPzmnCCA2fK"
      },
      "source": [
        "# Sacaling data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5OVELXCA97Y"
      },
      "source": [
        "y_pred = []\n",
        "len_x = len(X_train[0])\n",
        "w = []\n",
        "b = 0.2\n",
        "print(len_x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKV85QJPBKWm"
      },
      "source": [
        "entries = len(X_train[:,0])\n",
        "entries"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dn_LISPpBPrM"
      },
      "source": [
        "for weights in range(len_x):\n",
        "    w.append(0)\n",
        "w"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZt1xnygBRz0"
      },
      "source": [
        "# Sigmoid function\n",
        "def sigmoid(z):\n",
        "  return 1/(1+np.exp(-z))\n",
        "\n",
        "def predict(inputs,w):\n",
        "    z=np.dot(inputs,w)\n",
        "    return sigmoid(z)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXw9xTUuBh2b"
      },
      "source": [
        "#Loss function\n",
        "def loss_func(features,labels,w):\n",
        "    observations = len(labels)\n",
        "    predictions = predict(features, w)\n",
        "    class1_cost = -labels*np.log(predictions)\n",
        "    class2_cost = (1-labels)*np.log(1-predictions)\n",
        "    cost = class1_cost - class2_cost\n",
        "    cost = cost.sum() / observations\n",
        "    return cost\n",
        "\n",
        "dw = []\n",
        "db = 0\n",
        "J = 0\n",
        "alpha = 0.1\n",
        "for x in range(len_x):\n",
        "    dw.append(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SwAxfxyBtLF"
      },
      "source": [
        "def update_weights(features, labels, weights, lr):    \n",
        "    \n",
        "    N = len(features)    \n",
        "    predictions = predict(features, weights)    \n",
        "    gradient = np.dot(features.T,  predictions - labels)    \n",
        "    gradient /= N    \n",
        "    gradient *= lr    \n",
        "    weights -= gradient\n",
        "\n",
        "    return weights\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NUw9xiSCgqo"
      },
      "source": [
        "#Repeating the process 3000 times\n",
        "cost_history = []\n",
        "for i in range(3000):\n",
        "    w = update_weights(X, label, w, alpha)\n",
        "\n",
        "    #Calculate error for auditing purposes\n",
        "    cost = loss_func(X, label, w)\n",
        "    cost_history.append(cost)\n",
        "\n",
        "    # Log Progress\n",
        "    if i % 1000 == 0:\n",
        "        print(\"iter: \"+ str(i) + \" cost: \"+str(cost))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnR2onIjDbHW"
      },
      "source": [
        "#Print weight\n",
        "w\n",
        "\n",
        "#print bias\n",
        "b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abxr98ubDmZf"
      },
      "source": [
        "#predicting the label\n",
        "predicted_labels=predict(X_test,w)\n",
        "\n",
        "#print actual and predicted values in a table\n",
        "predicted_labels,label\n",
        "\n",
        "# Calculating accuracy of prediction\n",
        "diff = predicted_labels - y_test\n",
        "acc=1.0 - (float(np.count_nonzero(diff)) / len(diff))\n",
        "acc\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aiXY6C_Duxg"
      },
      "source": [
        "# Fitting Logistic Regression to the Training set\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "LR = LogisticRegression(random_state = 151)\n",
        "\n",
        "#Fit\n",
        "LR=LR.fit(X_train,y_train)\n",
        "#predicting the test label with LR. Predict always takes X as input\n",
        "y_pred=LR.predict(X_test)\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}